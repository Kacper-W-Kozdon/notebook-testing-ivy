{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdUQjt3yPPb3bgoLfjrIXX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kacper-W-Kozdon/notebook-testing-ivy/blob/main/Sarcasm_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "R0L0bqun06-X"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import userdata\n",
        "import os"
      ],
      "metadata": {
        "id": "TWUtvjpJ1D2H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "rKK5m_cv1K8G",
        "outputId": "e016b8fc-9428-4f0d-cf57-89d1aa893efb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f6e0fb37-5c14-44c3-96a4-dfc8f76ddaf6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f6e0fb37-5c14-44c3-96a4-dfc8f76ddaf6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "6jnjxcsw1frb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "mlnfW_ga1kgf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "JsnDpbVD2XZm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beMOG3_t2kt0",
        "outputId": "bcb2b1a0-7ead-47eb-c741-d0858a782c28"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.7 / client 1.5.16)\n",
            "ref                                                          title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-----------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "syedanwarafridi/vehicle-sales-data                           Vehicle Sales Data                                  19MB  2024-02-21 20:16:17          10645        196  1.0              \n",
            "arnavvvvv/spotify-music                                      Top Spotify Songs                                   47KB  2024-03-06 05:20:29           2156         42  1.0              \n",
            "yaminh/smartphone-sale-dataset                               Smartphones Sales Dataset                           65KB  2024-03-03 16:48:27           2459         35  0.88235295       \n",
            "tarunrm09/climate-change-indicators                          Climate change Indicators                           34KB  2024-02-22 08:53:54           5626        120  1.0              \n",
            "sumanthnimmagadda/student-spending-dataset                   Student spending habits dataset.                    29KB  2024-03-05 15:01:06           1263         25  0.9411765        \n",
            "arnavvvvv/netflix-movies-and-tv-shows                        Netflix Movies and TV Shows                          1MB  2024-03-04 15:49:29           2212         48  1.0              \n",
            "nbroad/gemma-rewrite-nbroad                                  gemma-rewrite-nbroad                                 8MB  2024-03-03 04:52:39            530         59  1.0              \n",
            "kanchana1990/spotify-datapopular-hip-hop-artists-and-tracks  Spotify Data:Popular Hip-Hop  Artists and Tracksüé∂   16KB  2024-03-08 09:33:34            458         25  1.0              \n",
            "bhavikjikadara/student-study-performance                     Student Study Performance                            9KB  2024-03-07 06:14:09           1179         36  1.0              \n",
            "l3llff/banana                                                üçå | Banana Quality                                 271KB  2024-03-03 12:20:13           1831         41  1.0              \n",
            "zain280/data-science-salaries                                Data Science Salaries                                7KB  2024-02-27 13:26:58           1357         28  1.0              \n",
            "anandshaw2001/amazon-sales-dataset                           Amazon_Sales_Dataset                               256KB  2024-03-04 18:30:11           1878         36  0.88235295       \n",
            "ehababoelnaga/multiple-disease-prediction                    Multiple Disease Prediction                        285KB  2024-03-03 16:46:22            947         25  0.9411765        \n",
            "nelgiriyewithana/emotions                                    Emotions                                            16MB  2024-02-05 16:01:39           6674        180  1.0              \n",
            "mahad049/job-placement-dataset                               Job placement dataset                                6KB  2024-03-03 08:18:12           1796         37  0.9411765        \n",
            "parasrupani/coffee-distribution-across-94-counties           Coffee Distribution Across 94 Counties             220KB  2024-02-28 01:49:07           1476         32  1.0              \n",
            "mikhail1681/walmart-sales                                    Walmart Sales                                      122KB  2024-02-13 17:35:56           7005         98  1.0              \n",
            "zain280/titanic-data-set                                     Titanic Data set                                    22KB  2024-02-28 14:04:13           1240         32  1.0              \n",
            "divaniazzahra/world-population-dataset                       World Population Dataset                            19KB  2024-03-07 14:34:11            515         23  1.0              \n",
            "zain280/car-dataset                                          Car Dataset                                          1MB  2024-03-02 15:14:49           2138         35  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d danofer/sarcasm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erpFMZ-X3-D0",
        "outputId": "4cc94844-5e1d-4104-f457-4abd69882a41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sarcasm.zip to /content\n",
            " 98% 212M/216M [00:06<00:00, 44.9MB/s]\n",
            "100% 216M/216M [00:06<00:00, 35.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO7x-UtWJG14",
        "outputId": "034f06cd-e76c-4746-c636-973c3079cbc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'demos'...\n",
            "remote: Enumerating objects: 3152, done.\u001b[K\n",
            "remote: Counting objects: 100% (608/608), done.\u001b[K\n",
            "remote: Compressing objects: 100% (229/229), done.\u001b[K\n",
            "remote: Total 3152 (delta 440), reused 421 (delta 348), pack-reused 2544\u001b[K\n",
            "Receiving objects: 100% (3152/3152), 16.26 MiB | 23.29 MiB/s, done.\n",
            "Resolving deltas: 100% (1813/1813), done.\n",
            "fatal: destination path 'ivy' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Kacper-W-Kozdon/demos.git\n",
        "!git clone https://github.com/Kacper-W-Kozdon/ivy.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q ivy mlflow datasets>=2.14.5 nlp 2>/dev/null\n",
        "import ivy"
      ],
      "metadata": {
        "id": "UNPUacTlJ8M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "import gc  # For garbage collection to manage memory\n",
        "import re  # For regular expressions\n",
        "import numpy as np  # For numerical operations and arrays\n",
        "\n",
        "import warnings  # For handling warnings\n",
        "warnings.filterwarnings(\"ignore\")  # Ignore warning messages\n",
        "\n",
        "import torch  # PyTorch library for deep learning\n",
        "from transformers import AutoModel, AutoTokenizer  # Transformers library for natural language processing\n",
        "from transformers import TextDataset, LineByLineTextDataset, DataCollatorForLanguageModeling, \\\n",
        "pipeline, Trainer, TrainingArguments, DataCollatorWithPadding  # Transformers components for text processing\n",
        "from transformers import AutoModelForSequenceClassification  # Transformer model for sequence classification\n",
        "\n",
        "from nlp import Dataset  # Import custom 'Dataset' class for natural language processing tasks\n",
        "from imblearn.over_sampling import RandomOverSampler  # For oversampling to handle class imbalance\n",
        "import datasets  # Import datasets library\n",
        "from datasets import Dataset, Image, ClassLabel  # Import custom 'Dataset', 'ClassLabel', and 'Image' classes\n",
        "from transformers import pipeline  # Transformers library for pipelines\n",
        "from bs4 import BeautifulSoup  # For parsing HTML content\n",
        "\n",
        "import matplotlib.pyplot as plt  # For data visualization\n",
        "import itertools  # For working with iterators\n",
        "from sklearn.metrics import (  # Import various metrics from scikit-learn\n",
        "    accuracy_score,  # For calculating accuracy\n",
        "    roc_auc_score,  # For ROC AUC score\n",
        "    confusion_matrix,  # For confusion matrix\n",
        "    classification_report,  # For classification report\n",
        "    f1_score  # For F1 score\n",
        ")\n",
        "\n",
        "from datasets import load_metric  # Import load_metric function to load evaluation metrics\n",
        "\n",
        "from tqdm import tqdm  # For displaying progress bars\n",
        "tqdm.pandas()  # Enable progress bars for pandas operations"
      ],
      "metadata": {
        "id": "CTrf1K9BKZRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/demos/Contributor_demos/Sarcasm Detection/train-balanced-sarcasm.csv\")\n"
      ],
      "metadata": {
        "id": "8QqrDqp2Kual"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.drop_duplicates()\n",
        "df = df[['comment', 'label']]\n",
        "df = df[~df['comment'].isnull()]\n",
        "df = df[~df['label'].isnull()]\n",
        "print(df.sample(15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7op48Zv8RN6_",
        "outputId": "82bad112-5723-47b0-f2c0-668e61bd4883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  comment  label\n",
            "531718  because the american political model can be us...      1\n",
            "302525  Mary Kate and Ashely: Island Dance Party was c...      0\n",
            "698658  Egalitarianism is equality in all respects, no...      0\n",
            "411629  So you'd rather wait until a news article with...      0\n",
            "978426  Oh dear god how DARE they have a contest where...      1\n",
            "622068    Have you considered filming it and showing him?      0\n",
            "346420  One is younger and has made it to the NHL, and...      1\n",
            "640505  Poor guy in the back trying to see around the ...      0\n",
            "129036  Why is Booker better at defense than Justise W...      0\n",
            "841552             you've never joined the thieves guild?      0\n",
            "676458  **\"Backup Exec is not shit\"** ^^^^The ^^^^worl...      0\n",
            "870757  Why don't we all just buy the new iPhone so th...      1\n",
            "491654                               I know that feel :,(      0\n",
            "531004  Too late, I've already heard of the accident e...      1\n",
            "232621  The irony of refering to the Saint of Killers ...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_pandas(df)\n",
        "del df\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCC3X1B9QxcX",
        "outputId": "99a22477-a606-4f7d-bfe6-1662ffba392d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_corpus():\n",
        "  training_corpus = (\n",
        "    dataset[\"comment\"][i : i + 1000]\n",
        "    for i in range(0, len(dataset[\"comment\"]), 1000)\n",
        "  )\n",
        "  return training_corpus\n",
        "\n",
        "training_corpus = get_training_corpus()\n"
      ],
      "metadata": {
        "id": "gn_D2Tj8pwPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "3hzlUnC4qI7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)"
      ],
      "metadata": {
        "id": "64vKSUFiqjCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"Sarcasm_Detection-Tokenizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3asJmcxIqow0",
        "outputId": "d606a642-3f50-43cf-b978-f7fc4e58c82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Sarcasm_Detection-Tokenizer/tokenizer_config.json',\n",
              " 'Sarcasm_Detection-Tokenizer/special_tokens_map.json',\n",
              " 'Sarcasm_Detection-Tokenizer/vocab.json',\n",
              " 'Sarcasm_Detection-Tokenizer/merges.txt',\n",
              " 'Sarcasm_Detection-Tokenizer/added_tokens.json',\n",
              " 'Sarcasm_Detection-Tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3C7FTwRDRIM",
        "outputId": "6a3e6cbd-aa0a-405d-8893-6c7115b03d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(dataset[\"comment\"][1], dataset[\"label\"][1])\n",
        "tokens = tokenizer(dataset[\"comment\"][1:5], padding=True)\n",
        "print(tokens)\n",
        "decoded_string = tokenizer.decode(tokens.get(\"input_ids\")[0])\n",
        "print(decoded_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD5d4HNx7YVU",
        "outputId": "2dbe81ca-1ef0-44c0-c6b2-e295bfeb9d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You do know west teams play against west teams more than east teams right? 0\n",
            "{'input_ids': [[446, 363, 465, 5140, 2347, 528, 1095, 5140, 2347, 506, 525, 5338, 2347, 539, 31, 52000, 52000, 52000, 52000, 52000, 52000, 52000, 52000], [741, 631, 42310, 4887, 1953, 12, 392, 1014, 18461, 312, 10837, 371, 15283, 12, 265, 9009, 1698, 515, 5277, 284, 14656, 742, 17], [677, 3195, 781, 320, 1460, 3407, 302, 265, 470, 9154, 25745, 12973, 2, 1671, 354, 14, 52000, 52000, 52000, 52000, 52000, 52000, 52000], [41, 609, 713, 479, 302, 646, 7910, 14, 52000, 52000, 52000, 52000, 52000, 52000, 52000, 52000, 52000, 52000, 52000, 52000, 52000, 52000, 52000]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "You do know west teams play against west teams more than east teams right?[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ivy.stateful.module import Module\n",
        "from ivy.stateful.sequential import Sequential\n",
        "from ivy.stateful.layers import *\n",
        "from ivy.stateful.losses import *\n",
        "from ivy.stateful.optimizers import *\n",
        "from ivy.stateful.activations import *\n",
        "from ivy.stateful.initializers import *\n",
        "from ivy.stateful.norms import *"
      ],
      "metadata": {
        "id": "ES3hc4GA7sVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQV8XOoNABH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}