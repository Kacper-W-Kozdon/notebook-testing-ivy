{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8ymTtMRdx8P+UbElMuaFQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kacper-W-Kozdon/notebook-testing-ivy/blob/main/Testing_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTV5Cp2PFSjC",
        "outputId": "4b10a42e-4db1-4a72-f87b-3241dd54c96e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4, 5, 6, 7], [8, 9]]\n"
          ]
        }
      ],
      "source": [
        "lst = [[1, 2, 3],\n",
        "       [4, 5, 6, 7],\n",
        "       [8, 9]]\n",
        "print(lst[1:3][0:2])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def wrap(fun):\n",
        "  def wrapper(*args, **kwargs):\n",
        "    print(fun.__doc__)\n",
        "    return fun\n",
        "  return wrapper\n",
        "\n",
        "@wrap\n",
        "def fun():\n",
        "  '''\n",
        "  asdfasdf\n",
        "  '''\n",
        "fun()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hfmu8eYnFqaw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30dded7-8e30-4328-b7af-5a5cf1987a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  asdfasdf\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.fun()>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q56NAEkVfMiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = 0\n",
        "a = list([0])\n",
        "\n",
        "\n",
        "def test_fun():\n",
        "  global x\n",
        "  x += 1\n",
        "\n",
        "def test_fun2(x):\n",
        "  x += 1\n",
        "  return x\n",
        "\n",
        "def test_fun3(x = x):\n",
        "  def inside(fun, *args, **kwargs):\n",
        "\n",
        "    return dict(**kwargs)\n",
        "  print(inside(test_fun3))\n",
        "  print()\n",
        "  print(vars())\n",
        "  print(globals())\n",
        "  vars().__setitem__(str(a), list([2]))\n",
        "  print(vars())\n",
        "  x[:] = [1, 2, 3]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_fun()\n",
        "test_fun2(x)\n",
        "test_fun3(x = a)\n",
        "print(x)\n",
        "print(a)\n",
        "\n"
      ],
      "metadata": {
        "id": "3zg8fx56OIrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a5ff3d-1431-4272-c4f9-418ee3834761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n",
            "\n",
            "{'x': [0], 'inside': <function test_fun3.<locals>.inside at 0x7b1e07b51090>}\n",
            "{'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'lst = [[1, 2, 3],\\n       [4, 5, 6, 7],\\n       [8, 9]]\\nprint(lst[1:3][0:2])', \"def wrap(fun):\\n  def wrapper(*args, **kwargs):\\n    print(fun.__doc__)\\n    return fun\\n  return wrapper\\n\\n@wrap\\ndef fun():\\n  '''\\n  asdfasdf\\n  '''\\nfun()\", 'x = 0\\na = list([0])\\n\\n\\ndef test_fun():\\n  global x\\n  x += 1\\n\\ndef test_fun2(x):\\n  x += 1\\n  return x\\n\\ndef test_fun3(x = x):\\n  def inside(fun, *args, **kwargs):\\n\\n    return dict(**kwargs)\\n  print(inside(test_fun3))\\n  print()\\n  print(vars())\\n  print(globals())\\n  vars().__setitem__(str(a), list([2]))\\n  print(vars())\\n  x[:] = [1, 2, 3]\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ntest_fun()\\ntest_fun2(x)\\ntest_fun3(x = a)\\nprint(x)\\nprint(a)'], '_oh': {2: <function fun at 0x7b1e07b51bd0>}, '_dh': ['/content'], 'In': ['', 'lst = [[1, 2, 3],\\n       [4, 5, 6, 7],\\n       [8, 9]]\\nprint(lst[1:3][0:2])', \"def wrap(fun):\\n  def wrapper(*args, **kwargs):\\n    print(fun.__doc__)\\n    return fun\\n  return wrapper\\n\\n@wrap\\ndef fun():\\n  '''\\n  asdfasdf\\n  '''\\nfun()\", 'x = 0\\na = list([0])\\n\\n\\ndef test_fun():\\n  global x\\n  x += 1\\n\\ndef test_fun2(x):\\n  x += 1\\n  return x\\n\\ndef test_fun3(x = x):\\n  def inside(fun, *args, **kwargs):\\n\\n    return dict(**kwargs)\\n  print(inside(test_fun3))\\n  print()\\n  print(vars())\\n  print(globals())\\n  vars().__setitem__(str(a), list([2]))\\n  print(vars())\\n  x[:] = [1, 2, 3]\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ntest_fun()\\ntest_fun2(x)\\ntest_fun3(x = a)\\nprint(x)\\nprint(a)'], 'Out': {2: <function fun at 0x7b1e07b51bd0>}, 'get_ipython': <bound method InteractiveShell.get_ipython of <google.colab._shell.Shell object at 0x7b1e20eaa5c0>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x7b1e20eaafb0>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x7b1e20eaafb0>, '_': <function fun at 0x7b1e07b51bd0>, '__': '', '___': '', '_i': \"\\ndef wrap(fun):\\n  def wrapper(*args, **kwargs):\\n    print(fun.__doc__)\\n    return fun\\n  return wrapper\\n\\n@wrap\\ndef fun():\\n  '''\\n  asdfasdf\\n  '''\\nfun()\", '_ii': 'lst = [[1, 2, 3],\\n       [4, 5, 6, 7],\\n       [8, 9]]\\nprint(lst[1:3][0:2])', '_iii': '', '_i1': 'lst = [[1, 2, 3],\\n       [4, 5, 6, 7],\\n       [8, 9]]\\nprint(lst[1:3][0:2])', 'lst': [[1, 2, 3], [4, 5, 6, 7], [8, 9]], '_i2': \"\\ndef wrap(fun):\\n  def wrapper(*args, **kwargs):\\n    print(fun.__doc__)\\n    return fun\\n  return wrapper\\n\\n@wrap\\ndef fun():\\n  '''\\n  asdfasdf\\n  '''\\nfun()\", 'wrap': <function wrap at 0x7b1e07b51c60>, 'fun': <function wrap.<locals>.wrapper at 0x7b1e07b51900>, '_2': <function fun at 0x7b1e07b51bd0>, '_i3': 'x = 0\\na = list([0])\\n\\n\\ndef test_fun():\\n  global x\\n  x += 1\\n\\ndef test_fun2(x):\\n  x += 1\\n  return x\\n\\ndef test_fun3(x = x):\\n  def inside(fun, *args, **kwargs):\\n\\n    return dict(**kwargs)\\n  print(inside(test_fun3))\\n  print()\\n  print(vars())\\n  print(globals())\\n  vars().__setitem__(str(a), list([2]))\\n  print(vars())\\n  x[:] = [1, 2, 3]\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ntest_fun()\\ntest_fun2(x)\\ntest_fun3(x = a)\\nprint(x)\\nprint(a)', 'x': 1, 'a': [0], 'test_fun': <function test_fun at 0x7b1e07b512d0>, 'test_fun2': <function test_fun2 at 0x7b1e07b517e0>, 'test_fun3': <function test_fun3 at 0x7b1e07b51b40>}\n",
            "{'x': [0], 'inside': <function test_fun3.<locals>.inside at 0x7b1e07b51090>, '[0]': [2]}\n",
            "1\n",
            "[1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_dict = {\"entry1\": 0, \"entry2\": 2}\n",
        "print(test_dict.get(\"entry1\"))\n",
        "print(test_dict.get(\"entry3\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU6jwDAdVzuv",
        "outputId": "f97a6896-b3e5-4455-a0e4-b1c35aaf9c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "y0RoyeSAWsCX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSqeGprORcYZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 2, 3, 4])\n",
        "b = torch.tensor([[5, 6], [7, 8]])\n",
        "print(a.reshape(b.shape))\n",
        "print(torch.reshape(a, b.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmjJHBqIRdw1",
        "outputId": "6d574a29-2ba6-4a9f-cbe6-bb94d79af8c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gather_old(\n",
        "    params: torch.Tensor,\n",
        "    indices: torch.Tensor,\n",
        "    /,\n",
        "    *,\n",
        "    axis: int = -1,\n",
        "    batch_dims: int = 0,\n",
        "    out: torch.Tensor = None,\n",
        ") -> torch.Tensor:\n",
        "    axis %= len(params.shape)\n",
        "    batch_dims %= len(params.shape)\n",
        "    result = []\n",
        "    if batch_dims == 0:\n",
        "\n",
        "\n",
        "      print(params.shape, indices.shape, params.shape < indices.shape, params.dim(), indices.dim())\n",
        "      dim_diff = params.dim() - indices.dim()\n",
        "      if dim_diff > 0:\n",
        "        params_squeezed = params\n",
        "        for d in range(dim_diff):\n",
        "          params_squeezed.squeeze(-1)\n",
        "        result = torch.take(\n",
        "              params_squeezed, indices.long(), out=None)\n",
        "        print(\"res: \", result)\n",
        "\n",
        "        print(\"shape: \", (params.shape[:axis] + indices.shape[batch_dims:]\n",
        "                                + params.shape[axis + 1 :]))\n",
        "        for d in range(dim_diff):\n",
        "          result = result.expand((params.shape[:axis] + indices.shape[batch_dims:]\n",
        "                                + params.shape[axis + 1 :]))\n",
        "\n",
        "        print(\"reshaped result: \", result)\n",
        "      else:\n",
        "        result = torch.take(\n",
        "              params, indices.long(), out=None)\n",
        "        print(\"else res: \", result)\n",
        "        print(\"shape: \", (params.shape[:axis] + indices.shape[batch_dims:]\n",
        "                                + params.shape[axis + 1 :]))\n",
        "        result = result.reshape((params.shape[:axis] + indices.shape[batch_dims:]\n",
        "                                + params.shape[axis + 1 :])\n",
        "                                )\n",
        "\n",
        "      print([*params.shape[0:batch_dims], *result.shape[1:]], (params.shape[:axis] + indices.shape[batch_dims:]\n",
        "                              + params.shape[axis + 1 :]), result, params.shape, indices.shape, params.shape > indices.shape, params.shape == indices.shape\n",
        "            )\n",
        "\n",
        "    else:\n",
        "        params_slices = torch.unbind(params, axis=0)\n",
        "        indices_slices = torch.unbind(indices, axis=0)\n",
        "        for b in range(batch_dims):\n",
        "            if b == 0:\n",
        "                zip_list = [(p, i) for p, i in zip(params_slices, indices_slices)]\n",
        "            else:\n",
        "                zip_list = [\n",
        "                    (p, i) for z in [zip(p1, i1) for p1, i1 in zip_list] for p, i in z\n",
        "                ]\n",
        "        for z in zip_list:\n",
        "            p, i = z\n",
        "            print(p.shape, i.reshape((-1, )).shape)\n",
        "            r = torch.gather(\n",
        "                p, (axis - batch_dims), torch.reshape(i.long(), (-1, )),\n",
        "                sparse_grad=False, out=None\n",
        "            )\n",
        "\n",
        "            result.append(r)\n",
        "        result = torch.stack(result)\n",
        "        #result = torch.cat(result, dim=0)\n",
        "        print(\"shape: \", (params.shape[:axis] + indices.shape[batch_dims:]\n",
        "                                + params.shape[axis + 1 :]))\n",
        "        result = result.reshape((params.shape[:axis] + indices.shape[batch_dims:]\n",
        "                                + params.shape[axis + 1 :])\n",
        "                                )\n",
        "    return result"
      ],
      "metadata": {
        "id": "WAPPpQnERuzc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gather(\n",
        "    params: torch.Tensor,\n",
        "    indices: torch.Tensor,\n",
        "    /,\n",
        "    *,\n",
        "    axis: int = -1,\n",
        "    batch_dims: int = 0,\n",
        "    out: torch.Tensor = None,\n",
        ") -> torch.Tensor:\n",
        "    axis %= len(params.shape)\n",
        "    axis = abs(len(params.shape) + axis) if axis < 0 else axis\n",
        "    print(f\"AXIS: {axis}\")\n",
        "    batch_dims %= len(params.shape)\n",
        "    result = []\n",
        "\n",
        "    def expand_p_i(params, indices):\n",
        "        ind_dim_helper_table = [1 for dim in list(indices.shape)]\n",
        "        ind_singleton_dims = torch.Size(ind_dim_helper_table)\n",
        "        param_singleton_dims_table = [1 for dim in list(params.shape)]\n",
        "        param_singleton_dims = torch.Size(param_singleton_dims_table)\n",
        "        print(\"INDICES SHAPE: \", indices.shape)\n",
        "        print(\"PARAMS SHAPE: \", params.shape)\n",
        "        print(f\"SINGLETON_DIMS: {param_singleton_dims}, {ind_singleton_dims}\")\n",
        "        print(\"RESHAPE SHAPE: \", param_singleton_dims[:axis]\n",
        "                                     + indices.shape[batch_dims:]\n",
        "                                     + param_singleton_dims[axis + 1:], \"\\n\",\n",
        "                                    params.shape[:axis]\n",
        "                                   + ind_singleton_dims[batch_dims:]\n",
        "                                   + params.shape[axis + 1:])\n",
        "        params_ex = params if (params.dim() <= 1) else \\\n",
        "                    params.reshape(params.shape[:axis]\n",
        "                                   + ind_singleton_dims\n",
        "                                   + params.shape[axis + 1:])\n",
        "        indices_ex = indices if (params.dim() <= 1) else \\\n",
        "                     indices.reshape(param_singleton_dims[:axis]\n",
        "                                     + indices.shape\n",
        "                                     + param_singleton_dims[axis + 1:])\n",
        "\n",
        "        print(\"FINAL SHAPE: \", params.shape[:axis]\n",
        "                                         + indices.shape\n",
        "                                         + params.shape[axis + 1:])\n",
        "        if (params.shape[:axis]\n",
        "           + indices.shape[batch_dims:]\n",
        "           + params.shape[axis + 1:]) != params_ex.shape:\n",
        "            params_ex = params_ex.expand(params.shape[:axis]\n",
        "                                         + indices.shape\n",
        "                                         + params.shape[axis + 1:])\n",
        "        if (params.shape[:axis]\n",
        "           + indices.shape[batch_dims:]\n",
        "           + params.shape[axis + 1:]) != indices_ex.shape:\n",
        "            indices_ex = indices_ex.expand(params.shape[:axis]\n",
        "                                           + indices.shape\n",
        "                                           + params.shape[axis + 1:])\n",
        "        print(\"EXPANDED SHAPES: \", params_ex.shape, indices_ex.shape)\n",
        "        return params_ex, indices_ex\n",
        "    if batch_dims == 0:\n",
        "        dim_diff = params.dim() - indices.dim()\n",
        "        if dim_diff != 0:\n",
        "            params_expanded, indices_expanded = expand_p_i(params, indices)\n",
        "            result = torch.gather(\n",
        "                                    params_expanded, axis,\n",
        "                                    indices_expanded.long(),\n",
        "                                    sparse_grad=False, out=out\n",
        "                                 )\n",
        "            return result\n",
        "        else:\n",
        "            result = torch.gather(\n",
        "                params, axis, indices.long(), sparse_grad=False, out=out)\n",
        "            result = result.reshape((params.shape[:axis]\n",
        "                                    + indices.shape[batch_dims:]\n",
        "                                    + params.shape[axis + 1:])\n",
        "                                    )\n",
        "    else:\n",
        "        params_slices = torch.unbind(params, axis=0)\n",
        "        indices_slices = torch.unbind(indices, axis=0)\n",
        "        for b in range(batch_dims):\n",
        "            if b == 0:\n",
        "                zip_list = [(p, i) for\n",
        "                            p, i in\n",
        "                            zip(params_slices, indices_slices)\n",
        "                            ]\n",
        "            else:\n",
        "                zip_list = [\n",
        "                           (p, i) for z in [zip(p1, i1) for p1, i1 in zip_list]\n",
        "                           for p, i in z\n",
        "                            ]\n",
        "        for z in zip_list:\n",
        "            p, i = z\n",
        "            dim_diff = p.dim() - i.dim()\n",
        "            p_expanded = p\n",
        "            i_expanded = i\n",
        "            if dim_diff != 0:\n",
        "              p_expanded, i_expanded = expand_p_i(p, i)\n",
        "            print(\"p, i shapes: \", p_expanded.shape, i_expanded.shape)\n",
        "            r = torch.gather(\n",
        "                             p_expanded, (axis - batch_dims),\n",
        "                             i_expanded.long(),\n",
        "                             sparse_grad=False, out=None\n",
        "                            )\n",
        "\n",
        "            result.append(r)\n",
        "        result = torch.stack(result)\n",
        "        result = result.reshape(params.shape[:axis] + indices.shape[batch_dims:] + params.shape[axis + 1:])\n",
        "        print(\"FINAL RES SHAPE: \", result.shape)\n",
        "\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "qFw57Sz9ptK_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([[-1.],\n",
        "                 [ 1.],\n",
        "                 [ 1.]])\n",
        "\n",
        "indices = torch.tensor([[[0],\n",
        "                  [0]],\n",
        "\n",
        "                 [[0],\n",
        "                  [0]],\n",
        "\n",
        "                 [[0],\n",
        "                  [0]]])\n",
        "\n",
        "paramstf = tf.constant([[-1.],\n",
        "                 [ 1.],\n",
        "                 [ 1.]])\n",
        "\n",
        "indicestf = tf.constant([[[0],\n",
        "                  [0]],\n",
        "\n",
        "                 [[0],\n",
        "                  [0]],\n",
        "\n",
        "                 [[0],\n",
        "                  [0]]])\n",
        "\n",
        "axis = 1\n",
        "batch_dims = 1\n",
        "\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "torch_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor)\n",
        "tf_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-dGjdSpTKBt",
        "outputId": "2c2bc462-47b6-4647-c2cc-7c7330875b8d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf:  tf.Tensor(\n",
            "[[[-1.]\n",
            "  [-1.]]\n",
            "\n",
            " [[ 1.]\n",
            "  [ 1.]]\n",
            "\n",
            " [[ 1.]\n",
            "  [ 1.]]], shape=(3, 2, 1), dtype=float32)\n",
            "\n",
            "\n",
            "AXIS: 1\n",
            "INDICES SHAPE:  torch.Size([2, 1])\n",
            "PARAMS SHAPE:  torch.Size([1])\n",
            "SINGLETON_DIMS: torch.Size([1]), torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) \n",
            " torch.Size([1, 1])\n",
            "FINAL SHAPE:  torch.Size([1, 2, 1])\n",
            "EXPANDED SHAPES:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "p, i shapes:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "INDICES SHAPE:  torch.Size([2, 1])\n",
            "PARAMS SHAPE:  torch.Size([1])\n",
            "SINGLETON_DIMS: torch.Size([1]), torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) \n",
            " torch.Size([1, 1])\n",
            "FINAL SHAPE:  torch.Size([1, 2, 1])\n",
            "EXPANDED SHAPES:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "p, i shapes:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "INDICES SHAPE:  torch.Size([2, 1])\n",
            "PARAMS SHAPE:  torch.Size([1])\n",
            "SINGLETON_DIMS: torch.Size([1]), torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) \n",
            " torch.Size([1, 1])\n",
            "FINAL SHAPE:  torch.Size([1, 2, 1])\n",
            "EXPANDED SHAPES:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "p, i shapes:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "FINAL RES SHAPE:  torch.Size([3, 2, 1])\n",
            "torch:  tensor([[[-1.],\n",
            "         [-1.]],\n",
            "\n",
            "        [[ 1.],\n",
            "         [ 1.]],\n",
            "\n",
            "        [[ 1.],\n",
            "         [ 1.]]])\n",
            "AXIS: 1\n",
            "INDICES SHAPE:  torch.Size([2, 1])\n",
            "PARAMS SHAPE:  torch.Size([1])\n",
            "SINGLETON_DIMS: torch.Size([1]), torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) \n",
            " torch.Size([1, 1])\n",
            "FINAL SHAPE:  torch.Size([1, 2, 1])\n",
            "EXPANDED SHAPES:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "p, i shapes:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "INDICES SHAPE:  torch.Size([2, 1])\n",
            "PARAMS SHAPE:  torch.Size([1])\n",
            "SINGLETON_DIMS: torch.Size([1]), torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) \n",
            " torch.Size([1, 1])\n",
            "FINAL SHAPE:  torch.Size([1, 2, 1])\n",
            "EXPANDED SHAPES:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "p, i shapes:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "INDICES SHAPE:  torch.Size([2, 1])\n",
            "PARAMS SHAPE:  torch.Size([1])\n",
            "SINGLETON_DIMS: torch.Size([1]), torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) \n",
            " torch.Size([1, 1])\n",
            "FINAL SHAPE:  torch.Size([1, 2, 1])\n",
            "EXPANDED SHAPES:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "p, i shapes:  torch.Size([1, 2, 1]) torch.Size([1, 2, 1])\n",
            "FINAL RES SHAPE:  torch.Size([3, 2, 1])\n",
            "\n",
            "tf.Tensor(\n",
            "[[[ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]]], shape=(3, 2, 1), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([0])\n",
        "\n",
        "indices = torch.tensor([0, 0])\n",
        "\n",
        "paramstf = tf.constant([0])\n",
        "\n",
        "indicestf = tf.constant([0, 0])\n",
        "\n",
        "axis = 0\n",
        "batch_dims = 0\n",
        "\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor, dtype = \"int32\")\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRo18trYTVsG",
        "outputId": "8e624918-0c2e-4672-db95-375a7dbace73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf:  tf.Tensor([0 0], shape=(2,), dtype=int32)\n",
            "\n",
            "\n",
            "AXIS: 0\n",
            "torch:  tensor([0, 0])\n",
            "AXIS: 0\n",
            "torch_to_tf:  tf.Tensor([0 0], shape=(2,), dtype=int32)\n",
            "\n",
            "tf.Tensor([ True  True], shape=(2,), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([-1])\n",
        "\n",
        "indices = torch.tensor([[0]])\n",
        "\n",
        "paramstf = tf.constant([-1])\n",
        "\n",
        "indicestf = tf.constant([[0]])\n",
        "\n",
        "axis = 0\n",
        "batch_dims = 0\n",
        "\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor, dtype = \"int32\")\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U7ApWFeXEw_",
        "outputId": "c1b42c6f-9ae5-4349-f4f4-7a9c6690553d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf:  tf.Tensor([[-1]], shape=(1, 1), dtype=int32)\n",
            "\n",
            "\n",
            "AXIS: 0\n",
            "INDICES SHAPE:  torch.Size([1, 1])\n",
            "PARAMS SHAPE:  torch.Size([1])\n",
            "SINGLETON_DIMS: torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) torch.Size([1, 1])\n",
            "FINAL SHAPE:  torch.Size([1, 1])\n",
            "EXPANDED SHAPES:  torch.Size([1, 1]) torch.Size([1, 1])\n",
            "torch:  tensor([[-1]])\n",
            "AXIS: 0\n",
            "INDICES SHAPE:  torch.Size([1, 1])\n",
            "PARAMS SHAPE:  torch.Size([1])\n",
            "SINGLETON_DIMS: torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) torch.Size([1, 1])\n",
            "FINAL SHAPE:  torch.Size([1, 1])\n",
            "EXPANDED SHAPES:  torch.Size([1, 1]) torch.Size([1, 1])\n",
            "torch_to_tf:  tf.Tensor([[-1]], shape=(1, 1), dtype=int32)\n",
            "\n",
            "tf.Tensor([[ True]], shape=(1, 1), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([[-1]])\n",
        "\n",
        "indices = torch.tensor([0])\n",
        "\n",
        "paramstf = tf.constant([[-1]])\n",
        "\n",
        "indicestf = tf.constant([0])\n",
        "\n",
        "axis = 0\n",
        "batch_dims = 0\n",
        "\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor, dtype = \"int32\")\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWJuj44IaK3b",
        "outputId": "28ffdcde-b68f-41ac-f064-c5be54e32892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf:  tf.Tensor([[-1]], shape=(1, 1), dtype=int32)\n",
            "\n",
            "\n",
            "AXIS: 0\n",
            "INDICES SHAPE:  torch.Size([1])\n",
            "PARAMS SHAPE:  torch.Size([1, 1])\n",
            "SINGLETON_DIMS: torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) torch.Size([1, 1, 1])\n",
            "FINAL SHAPE:  torch.Size([1, 1])\n",
            "EXPANDED SHAPES:  torch.Size([1, 1]) torch.Size([1, 1])\n",
            "torch:  tensor([[-1]])\n",
            "AXIS: 0\n",
            "INDICES SHAPE:  torch.Size([1])\n",
            "PARAMS SHAPE:  torch.Size([1, 1])\n",
            "SINGLETON_DIMS: torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) torch.Size([1, 1, 1])\n",
            "FINAL SHAPE:  torch.Size([1, 1])\n",
            "EXPANDED SHAPES:  torch.Size([1, 1]) torch.Size([1, 1])\n",
            "torch_to_tf:  tf.Tensor([[-1]], shape=(1, 1), dtype=int32)\n",
            "\n",
            "tf.Tensor([[ True]], shape=(1, 1), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([0])\n",
        "\n",
        "indices = torch.tensor([0])\n",
        "\n",
        "paramstf = tf.constant([0])\n",
        "\n",
        "indicestf = tf.constant([0])\n",
        "\n",
        "axis = 0\n",
        "batch_dims = 0\n",
        "\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor, dtype = \"int32\")\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1XzxC7_eAcC",
        "outputId": "979c2821-8ecf-4a94-f688-25a688c5a5d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf:  tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "\n",
            "\n",
            "AXIS: 0\n",
            "torch:  tensor([0])\n",
            "AXIS: 0\n",
            "torch_to_tf:  tf.Tensor([0], shape=(1,), dtype=int32)\n",
            "\n",
            "tf.Tensor([ True], shape=(1,), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([[0],\n",
        "                 [0]])\n",
        "\n",
        "indices = torch.tensor([0])\n",
        "\n",
        "paramstf = tf.constant([[0],\n",
        "                 [0]])\n",
        "\n",
        "indicestf = tf.constant([0])\n",
        "\n",
        "axis = 1\n",
        "batch_dims = 0\n",
        "\n",
        "\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor, dtype = \"int32\")\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHXhCfN5le44",
        "outputId": "6ca07bb4-b553-445b-9bb4-56e6e3f5f360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf:  tf.Tensor(\n",
            "[[0]\n",
            " [0]], shape=(2, 1), dtype=int32)\n",
            "\n",
            "\n",
            "AXIS: 1\n",
            "INDICES SHAPE:  torch.Size([1])\n",
            "PARAMS SHAPE:  torch.Size([2, 1])\n",
            "SINGLETON_DIMS: torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) torch.Size([2, 1, 1])\n",
            "FINAL SHAPE:  torch.Size([2, 1])\n",
            "EXPANDED SHAPES:  torch.Size([2, 1]) torch.Size([2, 1])\n",
            "torch:  tensor([[0],\n",
            "        [0]])\n",
            "AXIS: 1\n",
            "INDICES SHAPE:  torch.Size([1])\n",
            "PARAMS SHAPE:  torch.Size([2, 1])\n",
            "SINGLETON_DIMS: torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) torch.Size([2, 1, 1])\n",
            "FINAL SHAPE:  torch.Size([2, 1])\n",
            "EXPANDED SHAPES:  torch.Size([2, 1]) torch.Size([2, 1])\n",
            "torch_to_tf:  tf.Tensor(\n",
            "[[0]\n",
            " [0]], shape=(2, 1), dtype=int32)\n",
            "\n",
            "tf.Tensor(\n",
            "[[ True]\n",
            " [ True]], shape=(2, 1), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([[-13712,  25013, -11631,  -2072,  -7720, -29788, -27294]])\n",
        "\n",
        "indices = torch.tensor([3, 4, 1])\n",
        "\n",
        "paramstf = tf.constant([[-13712,  25013, -11631,  -2072,  -7720, -29788, -27294]])\n",
        "\n",
        "indicestf = tf.constant([3, 4, 1])\n",
        "\n",
        "axis = 1\n",
        "batch_dims = 0\n",
        "\n",
        "\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor, dtype = \"int32\")\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "LtAwBJEnNRZf",
        "outputId": "7e59ca8f-60df-408b-9e85-a34ad4d72849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf:  tf.Tensor([[-2072 -7720 25013]], shape=(1, 3), dtype=int32)\n",
            "\n",
            "\n",
            "AXIS: 1\n",
            "SINGLETON_DIMS: torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 3]) torch.Size([1, 1, 1])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d1cf95027673>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtf_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparamstf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicestf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtorch_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-74e81446bd9b>\u001b[0m in \u001b[0;36mgather\u001b[0;34m(params, indices, axis, batch_dims, out)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mdim_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdim_diff\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mparams_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_p_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             result = torch.gather(\n\u001b[1;32m     57\u001b[0m                                     \u001b[0mparams_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-74e81446bd9b>\u001b[0m in \u001b[0;36mexpand_p_i\u001b[0;34m(params, indices)\u001b[0m\n\u001b[1;32m     40\u001b[0m            \u001b[0;34m+\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m            + params.shape[axis + 1:]) != params_ex.shape:\n\u001b[0;32m---> 42\u001b[0;31m             params_ex = params_ex.expand(params.shape[:axis]\n\u001b[0m\u001b[1;32m     43\u001b[0m                                          \u001b[0;34m+\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                          + params.shape[axis + 1:])\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (3) must match the existing size (7) at non-singleton dimension 1.  Target sizes: [1, 3].  Tensor sizes: [1, 7]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([[-1, -1]])\n",
        "\n",
        "indices = torch.tensor([0])\n",
        "\n",
        "paramstf = tf.constant([[-1, -1]])\n",
        "\n",
        "indicestf = tf.constant([0])\n",
        "\n",
        "axis = 0\n",
        "batch_dims = 0\n",
        "\n",
        "\n",
        "\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor, dtype = \"int32\")\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "id": "H6S64nm9dCgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([[-1]])\n",
        "\n",
        "indices = torch.tensor([[0]])\n",
        "\n",
        "paramstf = tf.constant([[-1]])\n",
        "\n",
        "indicestf = tf.constant([[0]])\n",
        "\n",
        "axis = 0\n",
        "batch_dims = 0\n",
        "\n",
        "\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor, dtype = \"int32\")\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "id": "SNeXmM8fg7CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1]])\n",
        "print(a.reshape((1, 1, 1)))"
      ],
      "metadata": {
        "id": "VHVpu0JWoOea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([[-1], [-1], [-1]])\n",
        "\n",
        "indices = torch.tensor([1])\n",
        "\n",
        "paramstf = tf.constant([[-1], [-1], [-1]])\n",
        "\n",
        "indicestf = tf.constant([1])\n",
        "\n",
        "axis = 0\n",
        "batch_dims = 0\n",
        "print(indices.unsqueeze(-1).unsqueeze(-1))\n",
        "print(params.squeeze(-1))\n",
        "print(params.dim(), indices.dim())\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor, dtype = \"int32\")\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "fii13QArv-6Z",
        "outputId": "013e909b-e260-4e27-b2f6-52d220e47a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1]]])\n",
            "tensor([-1, -1, -1])\n",
            "2 1\n",
            "tf:  tf.Tensor([[-1]], shape=(1, 1), dtype=int32)\n",
            "\n",
            "\n",
            "AXIS: 0\n",
            "SINGLETON_DIMS: torch.Size([1, 1])\n",
            "RESHAPE SHAPE:  torch.Size([1, 1]) torch.Size([1, 1, 1])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-221a76545e7b>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtf_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparamstf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicestf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtorch_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-74e81446bd9b>\u001b[0m in \u001b[0;36mgather\u001b[0;34m(params, indices, axis, batch_dims, out)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mdim_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdim_diff\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mparams_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_p_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             result = torch.gather(\n\u001b[1;32m     57\u001b[0m                                     \u001b[0mparams_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-74e81446bd9b>\u001b[0m in \u001b[0;36mexpand_p_i\u001b[0;34m(params, indices)\u001b[0m\n\u001b[1;32m     40\u001b[0m            \u001b[0;34m+\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m            + params.shape[axis + 1:]) != params_ex.shape:\n\u001b[0;32m---> 42\u001b[0;31m             params_ex = params_ex.expand(params.shape[:axis]\n\u001b[0m\u001b[1;32m     43\u001b[0m                                          \u001b[0;34m+\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                          + params.shape[axis + 1:])\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [1, 1].  Tensor sizes: [3, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.gather(torch.tensor([[-1], [-1], [-1]]), 0, torch.tensor([[1]]))"
      ],
      "metadata": {
        "id": "AEh2tBe22iJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([[0], [0], [1]])\n",
        "\n",
        "indices = torch.tensor([0])\n",
        "\n",
        "paramstf = tf.constant([[0], [0], [1]])\n",
        "\n",
        "indicestf = tf.constant([0])\n",
        "\n",
        "axis = 0\n",
        "batch_dims = 1\n",
        "\n",
        "print(params.dim(), indices.dim())\n",
        "\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor, dtype = \"int32\")\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "id": "SGNyJUkv3GUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([[0], [1]])\n",
        "\n",
        "indices = torch.tensor([[0], [0]])\n",
        "\n",
        "paramstf = tf.constant([[0], [1]])\n",
        "\n",
        "indicestf = tf.constant([[0]])\n",
        "\n",
        "axis = 1\n",
        "batch_dims = 0\n",
        "\n",
        "print(params.shape)\n",
        "print(indices.expand((indices.shape[0], params.shape[-1 - axis])))\n",
        "print(torch.gather(params, axis, indices))\n",
        "print(params.dim(), indices.dim())\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "torch_to_tf = tf.convert_to_tensor(torch_tensor, dtype = \"int32\")\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()\n",
        "print(tf_tensor == torch_to_tf)"
      ],
      "metadata": {
        "id": "oX8dX48VNUPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "axis = 1\n",
        "batch_dims = 0\n",
        "\n",
        "params = torch.tensor([[[0], [2]]])\n",
        "\n",
        "indices = torch.tensor([[[0], [0]], [[0], [0]]])\n",
        "print(\"xxx: \", params.shape[:2] + indices.shape + params.shape[2 + 1:])\n",
        "#params = params.expand((1, 2, 2))\n",
        "#params = params.unsqueeze(-1).unsqueeze(-1)\n",
        "params = params.expand(params.shape[:axis] + indices.shape + params.shape[axis + 1:])\n",
        "print(\"params shape: \", params.shape)\n",
        "indices = indices.unsqueeze(0).unsqueeze(2)\n",
        "indices = indices.expand(params.shape)\n",
        "\n",
        "paramstf = tf.constant([[[0], [2]]])\n",
        "\n",
        "indicestf = tf.constant([[[0], [0]], [[0], [0]]])\n",
        "print(paramstf.shape, indicestf.shape)\n",
        "\n",
        "print(torch.gather(params, axis, indices))\n",
        "print(tf.gather(paramstf, indicestf, axis, batch_dims = batch_dims))"
      ],
      "metadata": {
        "id": "HbyMAtyBOX4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1, 2]])\n",
        "a.shape\n",
        "a0 = a.expand((3, 3, 2))\n",
        "a = a0.reshape((3, 3, 1, 2))\n",
        "a = a.expand((3, 3, 2, 2))\n",
        "ai0 = torch.ones((3, 2))\n",
        "ai = ai0.reshape((1, 3, 2, 1))\n",
        "ai = ai.expand((3, 3, 2, 2))\n",
        "\n",
        "b = [1 for dim in list(a.shape)]\n",
        "c = torch.Size(b)\n",
        "d = torch.ones(c)\n",
        "\n",
        "restorch = torch.gather(a, 1, ai.long())\n",
        "torch_to_tf_a = tf.convert_to_tensor(a0, dtype = \"int32\")\n",
        "torch_to_tf_ai = tf.convert_to_tensor(ai0, dtype = \"int32\")\n",
        "print(torch_to_tf_a.shape, torch_to_tf_ai.shape)\n",
        "restf = tf.gather(torch_to_tf_a, torch_to_tf_ai, axis = 1, batch_dims = 0)\n",
        "print(restf)\n",
        "print()\n",
        "print(restorch.shape)\n",
        "restf == tf.convert_to_tensor(restorch, dtype = \"int32\")\n"
      ],
      "metadata": {
        "id": "-ofcesGfdRMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1])\n",
        "\n",
        "indices = torch.tensor([[0], [0]])\n",
        "\n",
        "paramstf = tf.constant([1])\n",
        "\n",
        "indicestf = tf.constant([[0], [0]])\n",
        "\n",
        "axis = -1\n",
        "batch_dims = 0\n",
        "\n",
        "print(params.shape)\n",
        "print(indices.expand((indices.shape[0], params.shape[-1 - axis])))\n",
        "print(params.shape[:axis] , indices.shape[batch_dims:] , params.shape[axis + 1:])\n",
        "print(params.dim(), indices.dim())\n",
        "print(\"tf: \", tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims))\n",
        "print()\n",
        "print()\n",
        "print(\"torch: \", gather(params, indices, axis = axis, batch_dims = batch_dims))\n",
        "tf_tensor = tf.gather(paramstf, indicestf, axis = axis, batch_dims = batch_dims)\n",
        "torch_tensor = gather(params, indices, axis = axis, batch_dims = batch_dims)\n",
        "print(torch_to_tf == tf.convert_to_tensor(torch_tensor, dtype = \"int32\"))\n",
        "print(\"torch_to_tf: \", torch_to_tf)\n",
        "print()"
      ],
      "metadata": {
        "id": "ImdDZFpWxmd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[[1]]])\n",
        "b = torch.tensor([-1, -1, -1])\n",
        "axis = 0\n",
        "batch_dims = 0\n",
        "print(a.shape, b.shape)\n",
        "print(a.reshape((1, 1, 1, 1)))\n",
        "print(a.shape[:axis], b.shape, a.shape[axis + 1:])\n",
        "\n",
        "a = a.expand((a.shape[:axis] + b.shape + a.shape[axis + 1:]))\n",
        "print(a)"
      ],
      "metadata": {
        "id": "yitiyZxikn2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "49McLCmcuU8U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}